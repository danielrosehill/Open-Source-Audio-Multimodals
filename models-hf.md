# Model Repositories (GitHub)

GitHub repositories for notable audio multimodal models.

---

## Kimi-Audio

Moonshot AI's audio multimodal model with hybrid architecture supporting both understanding and generation.

- **Repository:** [MoonshotAI/Kimi-Audio](https://github.com/MoonshotAI/Kimi-Audio)

---

## Step-Audio2

StepFun's second-generation audio model with improved capabilities.

- **Repository:** [stepfun-ai/Step-Audio2](https://github.com/stepfun-ai/Step-Audio2)

---

## Audio Flamingo

NVIDIA's audio understanding model built on the Flamingo architecture.

- **Repository:** [NVIDIA/audio-flamingo](https://github.com/NVIDIA/audio-flamingo)

---

## Ming-UniAudio

InclusionAI's unified audio model.

- **Repository:** [inclusionAI/Ming-UniAudio](https://github.com/inclusionAI/Ming-UniAudio)

---

## OmniVinci

NVIDIA's omni-modal model.

- **Repository:** [NVlabs/OmniVinci](https://github.com/NVlabs/OmniVinci)

---

## Qwen3-Omni

Alibaba's third-generation omni-modal model from the Qwen family.

- **Repository:** [QwenLM/Qwen3-Omni](https://github.com/QwenLM/Qwen3-Omni)

---

## Audio Intelligence

NVIDIA's audio intelligence toolkit and models.

- **Repository:** [NVIDIA/audio-intelligence](https://github.com/NVIDIA/audio-intelligence)
